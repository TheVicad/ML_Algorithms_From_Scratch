{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7538e52-0e0f-4203-975b-03b1c20584b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df964a7-86dc-4cd6-966d-819be1a03182",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b57ca-ec2b-4c8b-95f2-0afb3a728054",
   "metadata": {},
   "source": [
    "1. Инициализация\n",
    "    - Имеется набор данных $D$\n",
    "    - Инициализируется дерево $T$\n",
    "2. Рост дерева\n",
    "    - Рекурсивно для каждой ноды до достижения критерия останова:\n",
    "        - Для каждого признака $f$ и порогового значения $s$ набор данных в ноде $D_t$ разбивается на две подвыборки:\n",
    "            $$D_L=\\{x \\in D | x_f \\leqslant s\\}; \\ D_R=\\{x \\in D | x_f > s\\}$$\n",
    "        - Для каждого разбиения считается мера чистоты $I$.\n",
    "        - Для разбиения выбираются такие $f$ и $s$, которые минимизируют $I$: $argmin_{f,s}\\frac{|D_L|}{|D_t|}I(D_L) + \\frac{|D_R|}{|D_t|}I(D_R) $\n",
    "        - Производится разбиение $D_t$ на $D_L$ и $D_R$\n",
    "4. Предсказание\n",
    "    - Для каждого наблюдения осуществляется спуск от корня дерева до листьев в соотвествии с обученными $f$ и $s$ для узловых нод.\n",
    "    Исходя из этого алгоритм дерева решений не может экстраполировать\n",
    "    - Предсказание опредляется большинством голосов для классификации и средним для регрессии "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b1867-20c0-4b75-942e-51f5dbab65e9",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "546301de-dbb7-4d1f-9b93-c7079f8f251f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Node():\n",
    "    '''\n",
    "    Класс, сохраняющий основную информацию о ноде дерева\n",
    "    '''\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.feature = None        # индекс признака для сплита в ноде\n",
    "        self.split = None          # значения для сплита\n",
    "        self.left_node = None      # левая нода\n",
    "        self.right_node = None     # правая нода\n",
    "        self.leaf_value = None     # значение листа, если нода листовая\n",
    "        self.impurity = None       # чистота ноды\n",
    "        self.p = None              # пропорция наблюдений в ноде по отношению к N\n",
    "        \n",
    "    def set_params(self, feature: int, split: float, impurity: float = None, p: float = None) -> None:\n",
    "        '''\n",
    "        Устанавливает основные параметры ноды\n",
    "        '''\n",
    "        self.feature = feature\n",
    "        self.split = split\n",
    "        self.impurity = impurity\n",
    "        self.p = p\n",
    "        \n",
    "    def get_params(self) -> tuple[int, float]:\n",
    "        '''\n",
    "        Возвращает индекс признака и пороговое значание для сплита\n",
    "        '''\n",
    "        return self.feature, self.split    \n",
    "        \n",
    "    def set_child_nodes(self, left_node: 'instance', right_node: 'instance') -> None:\n",
    "        '''\n",
    "        Устанавливает дочерние ноды\n",
    "        '''\n",
    "        self.left_node  = left_node\n",
    "        self.right_node = right_node\n",
    "        \n",
    "    def get_left_node(self) -> 'instance':\n",
    "        '''\n",
    "        Возвращает левую ноду\n",
    "        '''\n",
    "        return self.left_node\n",
    "    \n",
    "    def get_right_node(self) -> 'instance':\n",
    "        '''\n",
    "        Возвращает правую ноду\n",
    "        '''\n",
    "        return self.right_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6fd635b5-9aea-4ba3-aceb-8116928fc4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseDecisionTree(ABC):\n",
    "    '''\n",
    "    Базовый класс для дерева решений. Реализован в упрощенной форме для образовательных целей.\n",
    "    \n",
    "    Для классификации мера чистоты - entropy\n",
    "    Для регрессии мера чистоты - mse\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, max_depth: int = 2, min_samples_split: int = 2) -> None:\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _calculate_impurity(self, data: np.array) -> float:\n",
    "        '''\n",
    "        Рассчитывает чистоту выборки/ноды.\n",
    "        '''\n",
    "        pass\n",
    "        \n",
    "    def _calculate_split_impurity(self, data_left: np.array, data_right: np.array) -> float:\n",
    "        '''\n",
    "        Расчитывает чистоту дочерних нод после сплита\n",
    "        '''\n",
    "        n = data_left.shape[0] + data_right.shape[0]\n",
    "        p_left = data_left.shape[0] / n\n",
    "        p_right = data_right.shape[0] / n\n",
    "        return p_left * self._calculate_impurity(data_left) + p_right * self._calculate_impurity(data_right)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _calculate_leaf_value(self, data: np.array) -> float:\n",
    "        '''\n",
    "        Расчитывает значение листа\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_splits(feature_values: np.array) -> np.array:\n",
    "        '''\n",
    "        Возвращает возможные значения для разбиения\n",
    "        '''\n",
    "        unique_values = np.unique(feature_values)\n",
    "        return (unique_values[:-1] + unique_values[1:]) / 2\n",
    "    \n",
    "    def _get_best_split(self, data: np.array) -> tuple[int, float, float]:\n",
    "        '''\n",
    "        Возвращает наиболее оптимальный признак и значение для сплита на основании чистоты в дочерних нодах\n",
    "        '''\n",
    "        min_impurity = None\n",
    "        best_feature = None\n",
    "        best_split = None\n",
    "        for feature in range(data[:, :-1].shape[1]):\n",
    "            splits = self.get_splits(data[:, feature])\n",
    "            for split in splits:\n",
    "                data_left = data[data[:, feature] <= split]\n",
    "                data_right = data[data[:, feature] > split]\n",
    "                if (data_left.shape[0] == 0) or (data_right.shape[0] == 0):\n",
    "                    continue\n",
    "                split_impurity = self._calculate_split_impurity(data_left, data_right)\n",
    "                if (min_impurity is None) or (split_impurity < min_impurity):\n",
    "                    min_impurity = split_impurity\n",
    "                    best_feature = feature\n",
    "                    best_split = split\n",
    "        return best_feature, best_split, self._calculate_impurity(data)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_split(data: np.array, feature: int, split: float) -> tuple[np.array, np.array]:\n",
    "        '''\n",
    "        Разделяет выборку на две части по признаку и значению\n",
    "        '''\n",
    "        return data[data[:, feature] <= split], data[data[:, feature] > split]\n",
    "    \n",
    "    def _grow_tree(self, node: 'class', data: np.array, depth: int) -> None:\n",
    "        '''\n",
    "        Строит дерево от корневой ноды\n",
    "        '''\n",
    "        if (depth == self.max_depth) or (data.shape[0] < self.min_samples_split) or (np.unique(data[:, -1]).shape[0] == 1):\n",
    "            node.leaf_value = self._calculate_leaf_value(data)\n",
    "            node.impurity = self._calculate_impurity(data)\n",
    "            node.p = data.shape[0] / self.n\n",
    "        else:\n",
    "            data_left = None\n",
    "            data_right = None\n",
    "            best_feature, best_split, node_impurity = self._get_best_split(data)\n",
    "            data_left, data_right = self.make_split(data, best_feature, best_split)\n",
    "            node.set_params(best_feature, best_split, node_impurity, data.shape[0] / self.n)\n",
    "            left_node = Node()\n",
    "            right_node = Node()\n",
    "            node.set_child_nodes(left_node, right_node)\n",
    "            self._grow_tree(node.get_left_node(), data_left, depth + 1)\n",
    "            self._grow_tree(node.get_right_node(), data_right, depth + 1)\n",
    "            \n",
    "    def _traverse_tree(self, node: 'class', data: np.array) -> float:\n",
    "        '''\n",
    "        Возвращает значение листа для наблюдения. Используется в предсказании.\n",
    "        '''\n",
    "        if node.leaf_value is None:\n",
    "            best_feture, best_split = node.get_params()\n",
    "            if data[best_feture] <= best_split:\n",
    "                return self._traverse_tree(node.get_left_node(), data)\n",
    "            else:\n",
    "                return self._traverse_tree(node.get_right_node(), data)\n",
    "        else:\n",
    "            return node.leaf_value   \n",
    "\n",
    "    def fit(self, X: np.array, y: np.array) -> None:\n",
    "        data = np.c_[X, y]\n",
    "        self.n, self.p = X.shape\n",
    "        self.tree = Node()\n",
    "        self._grow_tree(self.tree, data, 0)\n",
    "        self.feature_importances = np.zeros(self.p)\n",
    "        self._compute_feature_importance(self.tree)\n",
    "        self.feature_importances = self.feature_importances / np.sum(self.feature_importances)\n",
    "\n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        predictions = []\n",
    "        for row in range(X.shape[0]):\n",
    "            prediction = self._traverse_tree(self.tree, X[row, :])\n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def _compute_feature_importance(self, node: 'class') -> None:\n",
    "        '''\n",
    "        Расчитывает важность для каждого признака по всему дереву\n",
    "        '''\n",
    "        if node.leaf_value is None:\n",
    "            self.feature_importances[node.feature] += self._get_importance(node)\n",
    "            self._compute_feature_importance(node.get_left_node())\n",
    "            self._compute_feature_importance(node.get_right_node())\n",
    "            \n",
    "    def _get_importance(self, node: 'class') -> float:\n",
    "        '''\n",
    "        Расчитывает важность признака в конкретной ноде\n",
    "        '''\n",
    "        left_node = node.get_left_node()\n",
    "        right_node = node.get_right_node()\n",
    "        return node.p * node.impurity - left_node.impurity * left_node.p - right_node.impurity * right_node.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "540e2f6d-3a4d-4813-961e-cc8072633d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier_(BaseDecisionTree):\n",
    "    \n",
    "    def _calculate_impurity(self, data: np.array) -> float:\n",
    "        class_counts = np.unique(data[:, -1], return_counts=True)[1]\n",
    "        probabilities = class_counts / sum(class_counts)\n",
    "        return -sum(probabilities * np.log2(probabilities+1e-9))\n",
    "    \n",
    "    def _calculate_leaf_value(self, data: np.array) -> int:\n",
    "        classes = np.unique(data[:, -1], return_counts=True)\n",
    "        plural_class_idx = np.argmax(classes[1])\n",
    "        return classes[0][plural_class_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "97534e2d-0bdd-48a9-8cce-eae9a8f4bab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor_(BaseDecisionTree):\n",
    "\n",
    "    def _calculate_impurity(self, data: np.array) -> float:\n",
    "        y = data[:, -1]\n",
    "        y_mean = np.mean(y)\n",
    "        return np.sum((y - y_mean)**2) / y.shape[0]\n",
    "    \n",
    "    def _calculate_leaf_value(self, data: np.array) -> int:\n",
    "        y = data[:, -1]\n",
    "        return np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7b6a32a-0c15-4a55-b5c0-d9b24b37400c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=3, n_informative=3,  n_redundant=0, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ab5bae8-48e4-47d8-b24a-95e998eb0278",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Results---\n",
      "\n",
      "custom accuracy: 0.9\n",
      "sklearn accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "custom_model = DecisionTreeClassifier_(max_depth=4, min_samples_split=2)\n",
    "sklearn_model = DecisionTreeClassifier(max_depth=4, min_samples_split=2, criterion='entropy')\n",
    "custom_model.fit(X_train, y_train)\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "custom_pred = custom_model.predict(X_test)\n",
    "sklearn_pred = sklearn_model.predict(X_test)\n",
    "\n",
    "print('\\n---Results---\\n')\n",
    "print(f'custom accuracy: {accuracy_score(y_test, custom_pred).round(2)}')\n",
    "print(f'sklearn accuracy: {accuracy_score(y_test, sklearn_pred).round(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "219a2f9e-2949-4be1-8828-ecec7d1237bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79534016, 0.1469735 , 0.05768634])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4ded6be-8b5a-4424-8e2f-9457e7786d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79534016, 0.1469735 , 0.05768634])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a54076b0-55c1-4301-9b91-3a8a35896edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=3, n_informative=2, noise=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8277a485-b54b-4197-9da9-fae56f7714b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom MSE: 2325.927\n",
      "sklearn MSE: 2325.927\n"
     ]
    }
   ],
   "source": [
    "model_custom = DecisionTreeRegressor_(max_depth=4, min_samples_split=2)\n",
    "model_sklearn = DecisionTreeRegressor(max_depth=4, min_samples_split=2, criterion='squared_error')\n",
    "model_custom.fit(X_train, y_train)\n",
    "model_sklearn.fit(X_train, y_train)\n",
    "\n",
    "custom_pred = model_custom.predict(X_test)\n",
    "sklearn_pred = model_sklearn.predict(X_test)\n",
    "\n",
    "print(f'custom MSE: {mean_squared_error(y_test, custom_pred).round(3)}')\n",
    "print(f'sklearn MSE: {mean_squared_error(y_test, sklearn_pred).round(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35260dbb-5154-40bf-8116-63df7fc2e3e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60794398, 0.39205602, 0.        ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_custom.feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4bb012c7-3b04-4746-8990-03d2e34ea102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60794398, 0.39205602, 0.        ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sklearn.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c822-2fe8-4704-ac3b-da63739b2551",
   "metadata": {},
   "source": [
    "# Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09eef32-bcef-45e4-bfbf-be803cc9b8bd",
   "metadata": {},
   "source": [
    "1. Инициализация\n",
    "    - Имеется набор данных $D$\n",
    "    - Устанавливается размер ансамбля $B$, т.е. кол-во решающих деревьев в лесу\n",
    "    - Генерируется $B$ бутстрапированных выборок \n",
    "2. Рост леса\n",
    "    - Для каждой бустрапированной выборки $b=1,...,B$:\n",
    "        - Инициализируется дерево $T_b$, обучающаеся на выборке $b$. \n",
    "        - Для каждого дерева $T_b$:\n",
    "            - Выбирается случайная подвыборка признаков $F_{sub}$ из всего набора признаков $F$. Обычно $F_{sub}=\\sqrt{F}$\n",
    "            - Осуществляется рост дерева в соотвествии с общим алгоритмом дерева решений на основании $F_{sub}$\n",
    "            - Обученое дерево решений $T_b$ сохраняется\n",
    "            - (Опционально) Сохраняются out-of-bag наблюдения для дерева $T_b$, т.е. наблюдения, которые не попали в выборку $b$.\n",
    "    - (Опционально) Out-of-bag пердсказания усредняются и расчитывается out-of-bag error\n",
    "    - Формируется случайный лес, состоящий из $T_1,...,B$ решающих деревьев\n",
    "3. Предсказание\n",
    "    - Каждое наблюдение пропускается через ансамбль деревьев $T_1,...,B$, формируется $B$ предсказаний\n",
    "    - Финальное предсказание опредляется большинством голосов для классификации и средним для регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c29d81-4278-42d5-8422-677e81925353",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "663da6a9-9db4-488b-b29c-5a18eccd7242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseRandomForest(ABC):\n",
    "    '''\n",
    "    Базовый класс для алгоритма случайного леса. Реализован в упрощенной форме для образовательных целей.\n",
    "    '''\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        n_estimators: int = 100,\n",
    "        max_depth: int = None, \n",
    "        min_samples_split: int = 2,\n",
    "        max_features = 'sqrt'\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "        self._decision_trees = []\n",
    "        self.oob_predictions = defaultdict(list)\n",
    "        self.oob_score = None\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def _init_decision_tree(self) -> 'class':\n",
    "        '''\n",
    "        Инициализирует инстанс дерева решений\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _compute_oob_score(self, y_train: np.array, oob_predictions: dict[list]) -> float:\n",
    "        '''\n",
    "        Рассчитывает оценку на oob выборке\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X: np.array, y: np.array) -> None:\n",
    "        '''\n",
    "        Обучает ансамбль деревьев и рассчитывает oob оценку\n",
    "        '''\n",
    "        n_samples, p_features = X.shape\n",
    "        row_idx = list(range(n_samples))\n",
    "        column_idx = list(range(p_features))\n",
    "        for b in range(self.n_estimators):\n",
    "            sample_row_idx = np.random.choice(row_idx, size=n_samples, replace=True)\n",
    "            X_sampled, y_sampled = X[sample_row_idx, :], y[sample_row_idx]\n",
    "            decision_tree = self._init_decision_tree()\n",
    "            decision_tree.fit(X_sampled, y_sampled)\n",
    "            self._decision_trees.append(decision_tree)\n",
    "            oob_row_idx = list(set(row_idx) - set(sample_row_idx))\n",
    "            if oob_row_idx:\n",
    "                oob_prediction = decision_tree.predict(X[oob_row_idx])\n",
    "                for idx, prediction in zip(oob_row_idx, oob_prediction):\n",
    "                    self.oob_predictions[idx].append(prediction)\n",
    "        self.oob_score = self._compute_oob_score(y, self.oob_predictions)\n",
    "        \n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        tree_predictions = []\n",
    "        for decision_tree in self._decision_trees:\n",
    "            prediction = decision_tree.predict(X).reshape(-1,1)\n",
    "            tree_predictions.append(prediction)\n",
    "        tree_predictions = np.concatenate(tree_predictions, axis=1)\n",
    "        return self._compute_ensemble_prediction(tree_predictions)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _compute_ensemble_prediction(self, tree_predictions: np.array) -> np.array:\n",
    "        '''\n",
    "        Рассчитывает финальное предсказание на основани мн-ва предсказаний ансамбля решающих деревьев\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e81abb8d-e615-47cf-a23c-1d61fe117bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomForestClassifier_(BaseRandomForest):\n",
    "        \n",
    "    def __init__(\n",
    "        self, \n",
    "        n_estimators: int = 100,\n",
    "        max_depth: int = None, \n",
    "        min_samples_split: int = 2,\n",
    "        max_features = 'sqrt',\n",
    "        criterion = 'entropy'\n",
    "    ):\n",
    "        super().__init__(n_estimators, max_depth, min_samples_split, max_features)\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        \n",
    "    def _init_decision_tree(self):\n",
    "        return DecisionTreeClassifier(\n",
    "                    max_depth = self.max_depth, \n",
    "                    min_samples_split = self.min_samples_split, \n",
    "                    max_features = self.max_features,\n",
    "                    criterion = self.criterion\n",
    "        )\n",
    "    \n",
    "    def _compute_oob_score(self, y_train, oob_predictions):\n",
    "        true_labels = np.array([y_train[idx] for idx in oob_predictions.keys()])\n",
    "        oob_prediction = np.array([np.bincount(predictions).argmax() for predictions in oob_predictions.values()])\n",
    "        return accuracy_score(true_labels, oob_prediction)\n",
    "    \n",
    "    def _compute_ensemble_prediction(self, tree_predictions):\n",
    "        return np.apply_along_axis(lambda predictions: np.bincount(predictions).argmax(), axis=1, arr=tree_predictions.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "57a7f231-30a5-481b-b3d9-bf19a6989b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomForestRegressor_(BaseRandomForest):\n",
    "        \n",
    "    def __init__(\n",
    "        self, \n",
    "        n_estimators: int = 100,\n",
    "        max_depth: int = None, \n",
    "        min_samples_split: int = 2,\n",
    "        max_features = 'sqrt',\n",
    "        criterion = 'squared_error'\n",
    "    ):\n",
    "        super().__init__(n_estimators, max_depth, min_samples_split, max_features)\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        \n",
    "    def _init_decision_tree(self):\n",
    "        return DecisionTreeRegressor(\n",
    "                    max_depth = self.max_depth, \n",
    "                    min_samples_split = self.min_samples_split, \n",
    "                    max_features = self.max_features,\n",
    "                    criterion = self.criterion\n",
    "        )\n",
    "    \n",
    "    def _compute_oob_score(self, y_train, oob_predictions):\n",
    "        true_labels = np.array([y_train[idx] for idx in oob_predictions.keys()])\n",
    "        oob_prediction = np.array([np.mean(predictions) for predictions in oob_predictions.values()])\n",
    "        return r2_score(true_labels, oob_prediction)\n",
    "    \n",
    "    def _compute_ensemble_prediction(self, tree_predictions):\n",
    "        return np.mean(tree_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "203c517e-d64a-4f34-8957-dca3f5c1467c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, n_features=10, n_informative=6,  n_redundant=0, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "17eb72e3-724c-462b-a478-624fc3f1a172",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Results---\n",
      "\n",
      "custom accuracy: 0.95\n",
      "sklearn accuracy: 0.95\n",
      "custom oob score: 0.954\n",
      "sklearn oob score: 0.951\n"
     ]
    }
   ],
   "source": [
    "custom_model = RandomForestClassifier_(n_estimators=100, max_depth=None, min_samples_split=2)\n",
    "sklearn_model = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, oob_score=True)\n",
    "custom_model.fit(X_train, y_train)\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "custom_pred = custom_model.predict(X_test)\n",
    "sklearn_pred = sklearn_model.predict(X_test)\n",
    "\n",
    "print('\\n---Results---\\n')\n",
    "print(f'custom accuracy: {accuracy_score(y_test, custom_pred).round(2)}')\n",
    "print(f'sklearn accuracy: {accuracy_score(y_test, sklearn_pred).round(2)}')\n",
    "print(f'custom oob score: {custom_model.oob_score.round(3)}')\n",
    "print(f'sklearn oob score: {sklearn_model.oob_score_.round(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1dddba6f-2967-429f-994b-e4fe0ed11ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=10000, n_features=10, n_informative=6, noise=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fb2be9ff-7cae-4ea5-a988-283e296d2344",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Results---\n",
      "\n",
      "custom MSE: 1136.98\n",
      "sklearn MSE: 1109.18\n",
      "custom oob score: 0.931\n",
      "sklearn oob score: 0.933\n"
     ]
    }
   ],
   "source": [
    "custom_model = RandomForestRegressor_(n_estimators=100, max_depth=None, min_samples_split=2)\n",
    "sklearn_model = RandomForestRegressor(n_estimators=100, max_depth=None, min_samples_split=2, max_features='sqrt', oob_score=True)\n",
    "custom_model.fit(X_train, y_train)\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "custom_pred = custom_model.predict(X_test)\n",
    "sklearn_pred = sklearn_model.predict(X_test)\n",
    "\n",
    "print('\\n---Results---\\n')\n",
    "print(f'custom MSE: {mean_squared_error(y_test, custom_pred).round(2)}')\n",
    "print(f'sklearn MSE: {mean_squared_error(y_test, sklearn_pred).round(2)}')\n",
    "print(f'custom oob score: {custom_model.oob_score.round(3)}')\n",
    "print(f'sklearn oob score: {sklearn_model.oob_score_.round(3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
